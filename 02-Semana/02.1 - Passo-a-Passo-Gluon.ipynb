{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02.1 - Passo-a-Passo-Gluon.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ed03SC1Jm9Yy"},"source":["# Deep Petro\n","\n","## Passo à Passo das Redes Neurais\n","\n","A criação e treinamento de uma rede neural tem alguns passos que foram um *pipeline* completo.\n","Nesta aula, vamos ver cada passo para criar e treinar uma rede neural do zero usando MXNet.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Gp6CwWnFnTwb"},"source":["Antes de começar, vamos instalar o MXNet. Esse pequeno bloco de código abaixo é usado somente para instalar o MXNet para CUDA 10. Execute esse bloco somente uma vez e ignore possíveis erros levantados durante a instalação.\n","\n","Configure também o Collab para fazer uso de GPUs.\n","\n","Clique em \"Runtime\" depois \"Change Runtime\" e por altere as configurações da seguinte forma:\n","\n","![](https://www.kdnuggets.com/wp-content/uploads/colab-settings-1.png)\n","\n","Antes de começar, vamos instalar o MXNet."]},{"cell_type":"code","metadata":{"id":"a-P9tmjlrfZD","colab_type":"code","colab":{}},"source":["!pip install mxnet-cu100"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QkdRWQBerfZP","colab_type":"text"},"source":["O próximo bloco contém nossos importes. O mais importante aqui é o gluon. Gluon é uma API mais alto nível para criação de redes neurais. Por baixo, temos um código estilo o de backpragation da aula passada. Porém, é bem melhor :-) Mais rápido, usa GPUs, carrega dados etc.\n","\n","Note como fazemos import de várias partes do gluon. Um código completo com mxnet + gluon vai fazer algo como:\n","\n","```python\n","from mxnet import autograd\n","from mxnet import gluon\n","from mxnet import init\n","from mxnet import nd\n","\n","from mxnet.gluon import data as gdata\n","from mxnet.gluon import loss as gloss\n","from mxnet.gluon import nn\n","from mxnet.gluon import utils\n","```"]},{"cell_type":"markdown","metadata":{"id":"o1S6HwvvrfZT","colab_type":"text"},"source":["Realizando os imports do Gluon, do MXNet, e de algumas bibliotecas básicas."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XW-VATPAldgt","colab":{}},"source":["from mxnet import autograd\n","from mxnet import gluon\n","from mxnet import init\n","from mxnet import nd\n","\n","from mxnet.gluon import data as gdata\n","from mxnet.gluon import loss as gloss\n","from mxnet.gluon import nn\n","from mxnet.gluon import utils\n","\n","import os\n","import sys\n","import time\n","import mxnet as mx\n","\n","import matplotlib.pyplot as plt\n","plt.ion()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hooT5vy2tUhD","colab_type":"text"},"source":["Abaixo configura o MXNet para fazer uso de GPUs."]},{"cell_type":"code","metadata":{"id":"J7otIerxtRi3","colab_type":"code","outputId":"0c1c5130-2a66-475c-ff4b-77695e42bbec","executionInfo":{"status":"ok","timestamp":1562081046235,"user_tz":180,"elapsed":766,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Tenta encontrar GPU\n","def try_gpu():\n","    try:\n","        ctx = mx.gpu()\n","        _ = nd.zeros((1,), ctx=ctx)\n","    except mx.base.MXNetError:\n","        ctx = mx.cpu()\n","    return ctx\n","\n","# CTX é um contexto mxnet, caso exista GPU o código rola nela. Caso não, executa na CPU mesmo.\n","ctx = try_gpu()\n","ctx"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["gpu(0)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Azv2ajIYkIjH"},"source":["## Passo 1: Carregar os dados\n","\n","Para treinar qualquer modelo de aprendizado de máquina, devemos carregar os dados.\n","Caso o modelo seja não supervisionado, teremos os dados somente.\n","Já para modelos treinados supervisionadamente, teremos os dados e os rótulos (também conhecidos como *labels* ou *ground-truths*).\n","\n","Obserne como o MXNET importa dados, pelo menos os didáticos, de forma muito simples."]},{"cell_type":"code","metadata":{"id":"ECtD5679rfZz","colab_type":"code","colab":{}},"source":["mnist_train = gdata.vision.MNIST(train=True)  # https://mxnet.incubator.apache.org/api/python/gluon/data.html#module-mxnet.gluon.data.vision\n","mnist_test = gdata.vision.MNIST(train=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ef6prhptrfZ7","colab_type":"text"},"source":["Cada conjunto acima agora é um iterador. Podemos passar pelos elementos"]},{"cell_type":"code","metadata":{"id":"H9NKaX1drfZ-","colab_type":"code","outputId":"fec845fe-9faf-40c6-d634-621e5ac6addc","executionInfo":{"status":"ok","timestamp":1562081052118,"user_tz":180,"elapsed":762,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["for xi, yi in mnist_train:\n","    print(xi.shape)\n","    print(yi)\n","    break"],"execution_count":36,"outputs":[{"output_type":"stream","text":["(28, 28, 1)\n","5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_pDHbgjArfaF","colab_type":"text"},"source":["No loop acima, vemos que o treino é uma image de 28, 28 por 1. A resposta é uma classe. A base é bem similar com as outras que usamo junto com skimage e é igual á que usamos na prática de ontem, com *MLP from scratch*."]},{"cell_type":"code","metadata":{"id":"sOcglLzxrfaI","colab_type":"code","outputId":"87587461-56d3-4b74-9542-82f8b8d4b358","executionInfo":{"status":"ok","timestamp":1562081055229,"user_tz":180,"elapsed":754,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["for xi, yi in mnist_train:\n","    print(type(xi))\n","    print(type(yi))\n","    break"],"execution_count":37,"outputs":[{"output_type":"stream","text":["<class 'mxnet.ndarray.ndarray.NDArray'>\n","<class 'numpy.int32'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UJvYG_LJrfaS","colab_type":"text"},"source":["O X é um TENSOR, o teste um inteiro. Como esperado, temos o número 5. Cada imagem é um número.\n","\n","Observe que precisei fazer um reshape para plotar, pois original o mxnet trabalha com tensores. Então, converti para uma imagem: (28, 28, 1) -> (28, 28)"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"y0BOWdDzrfaU","colab_type":"code","outputId":"7dee6cb9-fedb-466d-8ac0-1d378c02bd43","executionInfo":{"status":"ok","timestamp":1562081056900,"user_tz":180,"elapsed":746,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":275}},"source":["for xi, yi in mnist_train:\n","    Img = xi.reshape((28, 28))\n","    plt.matshow(Img.asnumpy())\n","    break"],"execution_count":38,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQACQCAQAiUAAkP4X+3ZSmGRvad8AAAAASUVORK5CYII=\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"gyFpdqfjrfac","colab_type":"text"},"source":["Vamos supor que nossa ideia fosse fazer uso de um multiplayer perceptron simples. O mesmo trabalha em cima de uma vetor. Portanto, temos que converter imagem ao carregar. Para isto, podemos fazer uso de um Transformer. Existe um mundo de [Transformers](https://mxnet.incubator.apache.org/api/python/gluon/data.html). Use o comando help para entender os mesmos."]},{"cell_type":"code","metadata":{"id":"QlhdwjW6rfad","colab_type":"code","outputId":"ebf23d07-12b0-4291-d7c1-5abcc98e9970","executionInfo":{"status":"ok","timestamp":1562081059501,"user_tz":180,"elapsed":631,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["help(gdata.vision.transforms.Cast)\n","gdata.vision.transforms.ToTensor\n","gdata.vision.transforms.Resize\n","gdata.vision.transforms.Normalize"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Help on class Cast in module mxnet.gluon.data.vision.transforms:\n","\n","class Cast(mxnet.gluon.block.HybridBlock)\n"," |  Cast input to a specific data type\n"," |  \n"," |  Parameters\n"," |  ----------\n"," |  dtype : str, default 'float32'\n"," |      The target data type, in string or `numpy.dtype`.\n"," |  \n"," |  \n"," |  Inputs:\n"," |      - **data**: input tensor with arbitrary shape.\n"," |  \n"," |  Outputs:\n"," |      - **out**: output tensor with the same shape as `data`.\n"," |  \n"," |  Method resolution order:\n"," |      Cast\n"," |      mxnet.gluon.block.HybridBlock\n"," |      mxnet.gluon.block.Block\n"," |      builtins.object\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __init__(self, dtype='float32')\n"," |      Initialize self.  See help(type(self)) for accurate signature.\n"," |  \n"," |  hybrid_forward(self, F, x)\n"," |      Overrides to construct symbolic graph for this `Block`.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      x : Symbol or NDArray\n"," |          The first input tensor.\n"," |      *args : list of Symbol or list of NDArray\n"," |          Additional input tensors.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from mxnet.gluon.block.HybridBlock:\n"," |  \n"," |  __setattr__(self, name, value)\n"," |      Registers parameters.\n"," |  \n"," |  cast(self, dtype)\n"," |      Cast this Block to use another data type.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      dtype : str or numpy.dtype\n"," |          The new data type.\n"," |  \n"," |  export(self, path, epoch=0)\n"," |      Export HybridBlock to json format that can be loaded by\n"," |      `SymbolBlock.imports`, `mxnet.mod.Module` or the C++ interface.\n"," |      \n"," |      .. note:: When there are only one input, it will have name `data`. When there\n"," |                Are more than one inputs, they will be named as `data0`, `data1`, etc.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      path : str\n"," |          Path to save model. Two files `path-symbol.json` and `path-xxxx.params`\n"," |          will be created, where xxxx is the 4 digits epoch number.\n"," |      epoch : int\n"," |          Epoch number of saved model.\n"," |  \n"," |  forward(self, x, *args)\n"," |      Defines the forward computation. Arguments can be either\n"," |      :py:class:`NDArray` or :py:class:`Symbol`.\n"," |  \n"," |  hybridize(self, active=True, **kwargs)\n"," |      Activates or deactivates :py:class:`HybridBlock` s recursively. Has no effect on\n"," |      non-hybrid children.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      active : bool, default True\n"," |          Whether to turn hybrid on or off.\n"," |      static_alloc : bool, default False\n"," |          Statically allocate memory to improve speed. Memory usage may increase.\n"," |      static_shape : bool, default False\n"," |          Optimize for invariant input shapes between iterations. Must also\n"," |          set static_alloc to True. Change of input shapes is still allowed\n"," |          but slower.\n"," |  \n"," |  infer_shape(self, *args)\n"," |      Infers shape of Parameters from inputs.\n"," |  \n"," |  infer_type(self, *args)\n"," |      Infers data type of Parameters from inputs.\n"," |  \n"," |  register_child(self, block, name=None)\n"," |      Registers block as a child of self. :py:class:`Block` s assigned to self as\n"," |      attributes will be registered automatically.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Methods inherited from mxnet.gluon.block.Block:\n"," |  \n"," |  __call__(self, *args)\n"," |      Calls forward. Only accepts positional arguments.\n"," |  \n"," |  __repr__(self)\n"," |      Return repr(self).\n"," |  \n"," |  apply(self, fn)\n"," |      Applies ``fn`` recursively to every child block as well as self.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      fn : callable\n"," |          Function to be applied to each submodule, of form `fn(block)`.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      this block\n"," |  \n"," |  collect_params(self, select=None)\n"," |      Returns a :py:class:`ParameterDict` containing this :py:class:`Block` and all of its\n"," |      children's Parameters(default), also can returns the select :py:class:`ParameterDict`\n"," |      which match some given regular expressions.\n"," |      \n"," |      For example, collect the specified parameters in ['conv1_weight', 'conv1_bias', 'fc_weight',\n"," |      'fc_bias']::\n"," |      \n"," |          model.collect_params('conv1_weight|conv1_bias|fc_weight|fc_bias')\n"," |      \n"," |      or collect all parameters whose names end with 'weight' or 'bias', this can be done\n"," |      using regular expressions::\n"," |      \n"," |          model.collect_params('.*weight|.*bias')\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      select : str\n"," |          regular expressions\n"," |      \n"," |      Returns\n"," |      -------\n"," |      The selected :py:class:`ParameterDict`\n"," |  \n"," |  initialize(self, init=<mxnet.initializer.Uniform object at 0x7f49eb759e80>, ctx=None, verbose=False, force_reinit=False)\n"," |      Initializes :py:class:`Parameter` s of this :py:class:`Block` and its children.\n"," |      Equivalent to ``block.collect_params().initialize(...)``\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      init : Initializer\n"," |          Global default Initializer to be used when :py:meth:`Parameter.init` is ``None``.\n"," |          Otherwise, :py:meth:`Parameter.init` takes precedence.\n"," |      ctx : Context or list of Context\n"," |          Keeps a copy of Parameters on one or many context(s).\n"," |      verbose : bool, default False\n"," |          Whether to verbosely print out details on initialization.\n"," |      force_reinit : bool, default False\n"," |          Whether to force re-initialization if parameter is already initialized.\n"," |  \n"," |  load_parameters(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n"," |      Load parameters from file previously saved by `save_parameters`.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      filename : str\n"," |          Path to parameter file.\n"," |      ctx : Context or list of Context, default cpu()\n"," |          Context(s) to initialize loaded parameters on.\n"," |      allow_missing : bool, default False\n"," |          Whether to silently skip loading parameters not represents in the file.\n"," |      ignore_extra : bool, default False\n"," |          Whether to silently ignore parameters from the file that are not\n"," |          present in this Block.\n"," |      \n"," |      References\n"," |      ----------\n"," |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n"," |  \n"," |  load_params(self, filename, ctx=None, allow_missing=False, ignore_extra=False)\n"," |      [Deprecated] Please use load_parameters.\n"," |      \n"," |      Load parameters from file.\n"," |      \n"," |      filename : str\n"," |          Path to parameter file.\n"," |      ctx : Context or list of Context, default cpu()\n"," |          Context(s) to initialize loaded parameters on.\n"," |      allow_missing : bool, default False\n"," |          Whether to silently skip loading parameters not represents in the file.\n"," |      ignore_extra : bool, default False\n"," |          Whether to silently ignore parameters from the file that are not\n"," |          present in this Block.\n"," |  \n"," |  name_scope(self)\n"," |      Returns a name space object managing a child :py:class:`Block` and parameter\n"," |      names. Should be used within a ``with`` statement::\n"," |      \n"," |          with self.name_scope():\n"," |              self.dense = nn.Dense(20)\n"," |      \n"," |      Please refer to\n"," |      `naming tutorial <http://mxnet.incubator.apache.org/tutorials/gluon/naming.html>`_\n"," |      for more info on prefix and naming.\n"," |  \n"," |  register_forward_hook(self, hook)\n"," |      Registers a forward hook on the block.\n"," |      \n"," |      The hook function is called immediately after :func:`forward`.\n"," |      It should not modify the input or output.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      hook : callable\n"," |          The forward hook function of form `hook(block, input, output) -> None`.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      :class:`mxnet.gluon.utils.HookHandle`\n"," |  \n"," |  register_forward_pre_hook(self, hook)\n"," |      Registers a forward pre-hook on the block.\n"," |      \n"," |      The hook function is called immediately before :func:`forward`.\n"," |      It should not modify the input or output.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      hook : callable\n"," |          The forward hook function of form `hook(block, input) -> None`.\n"," |      \n"," |      Returns\n"," |      -------\n"," |      :class:`mxnet.gluon.utils.HookHandle`\n"," |  \n"," |  save_parameters(self, filename)\n"," |      Save parameters to file.\n"," |      \n"," |      Saved parameters can only be loaded with `load_parameters`. Note that this\n"," |      method only saves parameters, not model structure. If you want to save\n"," |      model structures, please use :py:meth:`HybridBlock.export`.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      filename : str\n"," |          Path to file.\n"," |      \n"," |      References\n"," |      ----------\n"," |      `Saving and Loading Gluon Models         <https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html>`_\n"," |  \n"," |  save_params(self, filename)\n"," |      [Deprecated] Please use save_parameters. Note that if you want load\n"," |      from SymbolBlock later, please use export instead.\n"," |      \n"," |      Save parameters to file.\n"," |      \n"," |      filename : str\n"," |          Path to file.\n"," |  \n"," |  summary(self, *inputs)\n"," |      Print the summary of the model's output and parameters.\n"," |      \n"," |      The network must have been initialized, and must not have been hybridized.\n"," |      \n"," |      Parameters\n"," |      ----------\n"," |      inputs : object\n"," |          Any input that the model supports. For any tensor in the input, only\n"," |          :class:`mxnet.ndarray.NDArray` is supported.\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors inherited from mxnet.gluon.block.Block:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n"," |  \n"," |  name\n"," |      Name of this :py:class:`Block`, without '_' in the end.\n"," |  \n"," |  params\n"," |      Returns this :py:class:`Block`'s parameter dictionary (does not include its\n"," |      children's parameters).\n"," |  \n"," |  prefix\n"," |      Prefix of this :py:class:`Block`.\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["mxnet.gluon.data.vision.transforms.Normalize"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"VetOmO43rfak","colab_type":"text"},"source":["Vamos supor que você queira trabalhar com uma imagem em float32. Use um transformer!"]},{"cell_type":"code","metadata":{"id":"BqdSaebsrfam","colab_type":"code","outputId":"2d618a0c-2f31-4870-9aa9-2c4f259cf747","executionInfo":{"status":"ok","timestamp":1562081062593,"user_tz":180,"elapsed":787,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["xi, yi = next(iter(mnist_train))\n","print(xi.dtype)"],"execution_count":40,"outputs":[{"output_type":"stream","text":["<class 'numpy.uint8'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_bhJc8Nrrfau","colab_type":"code","outputId":"9830717b-3a6f-475f-9667-cc389d098443","executionInfo":{"status":"ok","timestamp":1562081064707,"user_tz":180,"elapsed":1322,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["transform = gdata.vision.transforms.Cast('float32')\n","xi_new = transform(xi)\n","print(xi_new.dtype)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["<class 'numpy.float32'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UKr9Ii11rfa1","colab_type":"text"},"source":["Podemos criar nossos transformers também! Por baixo são funções simples."]},{"cell_type":"code","metadata":{"id":"DY34qA57rfa2","colab_type":"code","colab":{}},"source":["def transform(xi, yi):\n","    return xi.reshape(28*28).astype('float32'), yi.astype('float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tv5v8ajdrfa9","colab_type":"code","outputId":"4da5718b-25f8-4696-a01f-c11f49484904","executionInfo":{"status":"ok","timestamp":1562081068914,"user_tz":180,"elapsed":846,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["xi_new, yi_new = transform(xi, yi)\n","print(xi_new.shape)\n","print(yi_new.dtype)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["(784,)\n","float32\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QGIYxPBArfbC","colab_type":"text"},"source":["Jogamos o transformer no carregamento dos dados e voilà!"]},{"cell_type":"code","metadata":{"id":"Hz4eLpHzrfbF","colab_type":"code","colab":{}},"source":["mnist_train = gdata.vision.MNIST(train=True, transform=transform)\n","mnist_test = gdata.vision.MNIST(train=False, transform=transform)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vFzvzuH3rfbJ","colab_type":"code","outputId":"cd631e0e-b6f9-4979-d15f-ff136cb165e4","executionInfo":{"status":"ok","timestamp":1562081073160,"user_tz":180,"elapsed":489,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["for xi, yi in mnist_train:\n","    print(xi.shape)\n","    print(xi.dtype)\n","    break"],"execution_count":45,"outputs":[{"output_type":"stream","text":["(784,)\n","<class 'numpy.float32'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ubw7WCF-rfbf","colab_type":"text"},"source":["Com a classe `gluon.data.DataLoader` conseguimos iterar pela base em minibatches. Esta é a ideia para executar um Minibatch-GD (abaixo)."]},{"cell_type":"code","metadata":{"id":"v3uWAkCarfbl","colab_type":"code","colab":{}},"source":["mnist_train = gdata.vision.MNIST(train=True, transform=transform)\n","mnist_test = gdata.vision.MNIST(train=False, transform=transform)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rlciqnQ7rfbt","colab_type":"code","colab":{}},"source":["minibatch_train = gluon.data.DataLoader(mnist_train, 50)\n","minibatch_test = gluon.data.DataLoader(mnist_test, 50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0SWoNgXprfb1","colab_type":"code","outputId":"71624c84-da09-407f-fb1d-daa70ca3d09d","executionInfo":{"status":"ok","timestamp":1562081078410,"user_tz":180,"elapsed":525,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["for xi, yi in minibatch_train:\n","    print(xi.shape) # note como carregamos 50 vetores de tamanho 784\n","    print(xi.dtype)\n","    break"],"execution_count":48,"outputs":[{"output_type":"stream","text":["(50, 784)\n","<class 'numpy.float32'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ms1VTmRTrfcF","colab_type":"text"},"source":["Uma prática comum que você pode ter nos seus dados é criar pastas de imagem de treino, teste e validação. Não temos isto pronto no notebook mas seria algo como o código abaixo. Note o uso de um `gluon.data.vision.ImageFolderDataset`.\n","\n","```python\n","# loading the data and apply pre-processing(transforms) on images\n","train_data = gluon.data.DataLoader(\n","    gluon.data.vision.ImageFolderDataset(train_path), transform=transformer,\n","    batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","\n","val_data = gluon.data.DataLoader(\n","    gluon.data.vision.ImageFolderDataset(val_path), transform=transformer,\n","    batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","\n","test_data = gluon.data.DataLoader(\n","    gluon.data.vision.ImageFolderDataset(test_path), transform=transformer,\n","    batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","```"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rRTTtpx4FhOC"},"source":["## Passo 2: Definir a arquitetura\n","\n","Um modelo deve ser definito para ser treinado usando os dados desejados.\n","No caso de redes neurais, criaremos uma nova arquitetura.\n","Tal arquitetura pode ser composta de diversos tipos de camadas como, por exemplo, [Densas](https://mxnet.incubator.apache.org/api/python/gluon/nn.html#mxnet.gluon.nn.Dense) (camadas totalmente conectadas como as que implementamos do zero), [convolucionais](https://mxnet.incubator.apache.org/api/python/gluon/nn.html#mxnet.gluon.nn.Conv2D), e [recorrentes](https://mxnet.incubator.apache.org/api/python/gluon/rnn.html#mxnet.gluon.rnn.RNN).\n","Veremos todas essas camadas ao longo do curso.\n","\n","O código abaixo cria uma rede simples MLP. Note como a mesma tem 10 saídas. A entrada não é definida, o mxnet é inteligente suficiente para adivinhar o formato da camada-zero usando os dados.\n","\n","(sim, o reshape de antes não serve de nada, mas ok, ajuda para aprender)"]},{"cell_type":"code","metadata":{"id":"GAPS5wnKrfcM","colab_type":"code","colab":{}},"source":["net = nn.Sequential()\n","net.add(nn.Dense(10))\n","net.initialize(init.Normal(sigma=0.01)) # valores iniciais são uma normal"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BAgtOMZKHqS9"},"source":["## Passo 3: Definir a função de custo (função de perda ou *loss*)\n","\n","Funções de perda, também conhecidas como *loss functions*, são muito importantes para o aprendizagem de máquinas, pois servem como uma forma de medir a distância ou a diferença entre a saída prevista de um modelo e o seu valor real, auxiliando então no treino no modelo.\n","\n","Diversas funções de perda foram propostas ao longo do tempo para diferentes tipos de problemas.\n","Algumas dessas funções foram propostas para auxiliar no treino de modelos de regressão linear, como as *loss* [L1](https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.L2Loss), [L2](https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.L1Loss).\n","Já outras foram propostas para problemas de classificação, como [Hinge](https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.HingeLoss), e [Cross Entropy](https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.SoftmaxCrossEntropyLoss).\n","\n","Veremos várias funções de custo mais adiante no curso.\n","Neste primeiro momento, focaremos na função [Cross Entropy](https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.SoftmaxCrossEntropyLoss)  combinada com a ativação [Softmax](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.Symbol.softmax), pois é a combinação mais comum nos dias de hoje para a tarefa de classificação.\n","\n","O pequeno bloco de código abaixo implementa essa função de perda em MXNet."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WVoEMNgBIt9v","colab":{}},"source":["# função de custo (ou loss)\n","cross_entropy = gloss.SoftmaxCrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BDJGM6GrJIeV"},"source":["## Passo 4: Definir o algoritmo de otimização\n","\n","Definimos uma arquitetura, composta de diversos pesos geralmente inicializados aleatoriamente, e definimos também uma função que custo que nos permite avaliar o quão bem esta rede neural está.\n","Entretanto, para que possamos alterar os pesos e fazer a rede convergir para um bom resultados, devemos definir um algoritmo de otimização, que usará derivadas parciais da função de custo em relação àos pesos para otimizar a rede.\n","\n","Diversos algoritmos foram propostos ao longo dos anos como, por exemplo, [Stochastic Gradient Descent (SGD)](https://mxnet.incubator.apache.org/api/python/optimization/optimization.html#mxnet.optimizer.SGD), [Adam](https://mxnet.incubator.apache.org/api/python/optimization/optimization.html#mxnet.optimizer.Adam), e [RMSProp](https://mxnet.incubator.apache.org/api/python/optimization/optimization.html#mxnet.optimizer.RMSProp).\n","Veremos mais adianta sobre cada um desses algoritmos.\n","Nesse primeiro momento, usaremos o algoritmo mais comum: [Stochastic Gradient Descent (SGD)](https://mxnet.incubator.apache.org/api/python/optimization/optimization.html#mxnet.optimizer.SGD).\n","\n","O código abaixo implementa uma função de otimização usando o SGD para otimizar todos os parâmetros da rede neural proposta."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SvJ1W-niJIGA","colab":{}},"source":["# trainer do gluon\n","lr = 0.5\n","trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fUYirh57rfcm","colab_type":"text"},"source":["### Treinando\n","\n","A partir deste momento já podemos treinar! Observe como a biblioteca permite de forma muito simples uma implementação do gradiente descendente"]},{"cell_type":"code","metadata":{"id":"YSQgfCo-rfcn","colab_type":"code","colab":{}},"source":["# 1. Carrega dados\n","mnist_train = gdata.vision.MNIST(train=True, transform=transform)\n","mnist_test = gdata.vision.MNIST(train=False, transform=transform)\n","\n","# 2. Define mini-batch\n","minibatch_train = gluon.data.DataLoader(mnist_train, 50)\n","minibatch_test = gluon.data.DataLoader(mnist_test, 50)\n","\n","# 3. Define rede\n","\n","net = nn.Sequential()\n","net.add(nn.Dense(10))\n","net.initialize(init.Normal(sigma=0.01)) # valores iniciais são uma normal\n","\n","# 4. Define loss e treinamento\n","cross_entropy = gloss.SoftmaxCrossEntropyLoss()\n","lr = 0.01\n","trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TOmbY28zrfcq","colab_type":"text"},"source":["Agora, treine!"]},{"cell_type":"code","metadata":{"id":"aU3I3fHQrfcr","colab_type":"code","outputId":"eac62314-6fa0-4b31-96d5-ec5e530251da","executionInfo":{"status":"ok","timestamp":1562081143215,"user_tz":180,"elapsed":53620,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["iteracoes_treino = 5\n","for i in range(iteracoes_treino):         # número de iterações, não verificamos convergencia\n","    cumulative_loss = 0\n","    for data, y in minibatch_train:       # para cada minibatch\n","        with mx.autograd.record():        # indicando que vamos derivar\n","            P = net(data)                 # execute o softmax, retorne as probabilidades, forward\n","            loss = cross_entropy(P, y)    # compute a perda\n","        loss.backward()                   # atualiza os pesos com backward, nosso backprop de antes\n","        trainer.step(data.shape[0])       # atualize os parâmetros com a derivada\n","        cumulative_loss += nd.sum(loss).asscalar()\n","    print('Iteração {}. Perda {}'.format(i+1, cumulative_loss / len(data)))"],"execution_count":53,"outputs":[{"output_type":"stream","text":["Iteração 1. Perda 323183.45391845703\n","Iteração 2. Perda 242848.6600006628\n","Iteração 3. Perda 231278.01515014647\n","Iteração 4. Perda 221024.00259974718\n","Iteração 5. Perda 218317.51611293643\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W8Tdqr2irfcx","colab_type":"text"},"source":["Podemos treinar aquiteturas mais complicadas. Abaixo, treinaremos uma arquitetura baseada na [LeNet-5](https://ieeexplore.ieee.org/document/726791).\n","\n","Notem que, além de definir o tipo da camada, é necessário também definir a sua ativação.\n","Existem diversos tipos de ativações como, por exemplo, [ReLU](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.Symbol.relu), [LeakyReLU](https://mxnet.incubator.apache.org/api/python/gluon/nn.html#mxnet.gluon.nn.LeakyReLU), e [sigmoid](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.Symbol.sigmoid).\n","Neste primeiro momento, usaremos somente a ReLU.\n","Porém, veremos mais de perto várias outras ativações ao longo deste curso.\n","\n","O trecho de código abaixo implementa uma rede simples usando [ReLUs](https://mxnet.incubator.apache.org/api/python/symbol/symbol.html#mxnet.symbol.Symbol.relu) no framework MXNet."]},{"cell_type":"code","metadata":{"id":"aNSC3Atxrfcy","colab_type":"code","colab":{}},"source":["# 1. Carrega dados\n","mnist_train = gdata.vision.MNIST(train=True, transform=transform)\n","mnist_test = gdata.vision.MNIST(train=False, transform=transform)\n","\n","# 2. Define mini-batch\n","minibatch_train = gluon.data.DataLoader(mnist_train, 50)\n","minibatch_test = gluon.data.DataLoader(mnist_test, 50)\n","\n","# 3. Define rede\n","\n","net = nn.Sequential()\n","net.add(nn.Dense(128, activation='relu'),\n","        nn.Dense(64, activation='relu'),\n","        nn.Dense(10))\n","net.initialize(init.Normal(sigma=0.01), ctx=ctx) # observe aqui o uso do ctx! use a GPU!!\n","\n","# 4. Define loss e treinamento\n","cross_entropy = gloss.SoftmaxCrossEntropyLoss()\n","lr = 0.5\n","trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RX6ADWXBrfc2","colab_type":"text"},"source":["Observe como nessa rede nova a perda é bem menor logo de cara, parece melhor!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FAEBKuhzHLeO","outputId":"bcb0e6cf-bad9-405b-ece8-8533f3222f48","executionInfo":{"status":"ok","timestamp":1562081383434,"user_tz":180,"elapsed":64100,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["iteracoes_treino = 5\n","for i in range(iteracoes_treino):         # número de iterações, não verificamos convergencia\n","    cumulative_loss = 0\n","    for data, y in minibatch_train:       # para cada minibatch\n","        data, y = data.as_in_context(ctx), y.as_in_context(ctx)  # converte o dado para GPU\n","        with mx.autograd.record():        # indicando que vamos derivar\n","            P = net(data)                 # execute o softmax, retorne as probabilidades, forward\n","            loss = cross_entropy(P, y)    # compute a perda\n","        loss.backward()                   # atualiza os pesos com backward, nosso backprop de antes\n","        trainer.step(data.shape[0])       # atualize os parâmetros com a derivada\n","        cumulative_loss += nd.sum(loss).asscalar()\n","    print('Iteração {}. Perda {}'.format(i+1, cumulative_loss / len(data)))"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Iteração 1. Perda 2.1902625241753566e+22\n","Iteração 2. Perda 2764.404112548828\n","Iteração 3. Perda 2764.40411239624\n","Iteração 4. Perda 2764.40411239624\n","Iteração 5. Perda 2764.40411239624\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_GRvKcMyrfc8","colab_type":"text"},"source":["Abaixo rodamos um minibatch apenas. Note como a rede gera previsões. Para cada instância, temos 10 elementos da camada final. A probabilidade de cada classe!"]},{"cell_type":"code","metadata":{"id":"ARnln34Hrfc-","colab_type":"code","outputId":"f6b96d52-b8fa-4fe9-b568-616130febd76","executionInfo":{"status":"ok","timestamp":1562081429583,"user_tz":180,"elapsed":696,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["for data, y in minibatch_test: \n","    data, y = data.as_in_context(ctx), y.as_in_context(ctx)\n","    P = net(data)                # faça uma previsão\n","    print(P.shape)\n","    break"],"execution_count":63,"outputs":[{"output_type":"stream","text":["(50, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1ExulxXDrfdC","colab_type":"text"},"source":["Abaixo avaliamos a acurácia no teste.\n","\n","Note o use da classe `mx.metric.Accuracy()`. A mesma acumula resultados para cada minibatch do teste. Sim, é esquisito, mas deixa a ideia de iterar por batches consistente em treino/teste."]},{"cell_type":"code","metadata":{"id":"e6hNjrHtrfdD","colab_type":"code","outputId":"960837bc-2094-4062-9d3b-7b2af8309433","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1562081444105,"user_tz":180,"elapsed":2627,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}}},"source":["from mxnet import metric\n","\n","acc = metric.Accuracy()\n","i = 0\n","for data, y in minibatch_test:            # para cada minibatch do teste\n","    data, y = data.as_in_context(ctx), y.as_in_context(ctx)\n","    P = net(data)                         # faça uma previsão\n","    pred = P.argmax(axis=1)               # pegue a classe mais provavel\n","    acc.update(preds = pred, labels = y)  # atualize a accuracy\n","print(acc)"],"execution_count":65,"outputs":[{"output_type":"stream","text":["EvalMetric: {'accuracy': 0.1028}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YkxA9w4sLX1L"},"source":["## Passo 5: Colando Tudo Junto\n","\n","\n","No geral, não vamos fazer isso sempre do zero. \n","\n","Portanto, abaixo implementamos algumas funções auxiliares. As mesmas carregam os dados, quebram treinam e validam, reportam métricas. Vamos usar elas nos outros notebooks.\n","\n","Portanto, criamos conjuntos de treino/validação. Este é último passo para então treinar a rede neural. Abixo, temos uma função que que recebe os dados, a rede, o *loss*, e o algoritmo de otimização, e realmente converge o modelo."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tlBGUroCFfyh","colab":{}},"source":["## carregando dados\n","\n","# código para carregar o dataset do MNIST\n","# http://yann.lecun.com/exdb/mnist/\n","def load_data_mnist(batch_size, resize=None, root=os.path.join(\n","        '~', '.mxnet', 'datasets', 'mnist')):\n","    \"\"\"Download the MNIST dataset and then load into memory.\"\"\"\n","    root = os.path.expanduser(root)\n","    transformer = []\n","    if resize:\n","        transformer += [gdata.vision.transforms.Resize(resize)]\n","    transformer += [gdata.vision.transforms.ToTensor()]\n","    transformer = gdata.vision.transforms.Compose(transformer)\n","\n","    mnist_train = gdata.vision.MNIST(root=root, train=True)\n","    mnist_test = gdata.vision.MNIST(root=root, train=False)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),\n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),\n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","\n","# funções básicas\n","def _get_batch(batch, ctx):\n","    \"\"\"Return features and labels on ctx.\"\"\"\n","    features, labels = batch\n","    if labels.dtype != features.dtype:\n","        labels = labels.astype(features.dtype)\n","    return (utils.split_and_load(features, ctx),\n","            utils.split_and_load(labels, ctx), features.shape[0])\n","\n","# Função usada para calcular acurácia\n","def evaluate_accuracy(data_iter, net, loss, ctx=[mx.cpu()]):\n","    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n","    if isinstance(ctx, mx.Context):\n","        ctx = [ctx]\n","    acc_sum, n, l = nd.array([0]), 0, 0\n","    for batch in data_iter:\n","        features, labels, _ = _get_batch(batch, ctx)\n","        for X, y in zip(features, labels):\n","            # X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            y = y.astype('float32')\n","            y_hat = net(X)\n","            l += loss(y_hat, y).sum()\n","            acc_sum += (y_hat.argmax(axis=1) == y).sum().copyto(mx.cpu())\n","            n += y.size\n","        acc_sum.wait_to_read()\n","    return acc_sum.asscalar() / n, l.asscalar() / n\n","  \n","# Função usada no treinamento e validação da rede\n","def train_validate(net, train_iter, test_iter, batch_size, trainer, loss, ctx,\n","                   num_epochs):\n","    print('training on', ctx)\n","    for epoch in range(num_epochs):\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","        for X, y in train_iter:\n","            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            with autograd.record():\n","                y_hat = net(X)\n","                l = loss(y_hat, y).sum()\n","            l.backward()\n","            trainer.step(batch_size)\n","            y = y.astype('float32')\n","            train_l_sum += l.asscalar()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n","            n += y.size\n","        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss, ctx)\n","        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n","              'test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_loss, \n","                 test_acc, time.time() - start))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xVz3s2qQrfdO","colab_type":"code","colab":{}},"source":["# carregamento do dado: mnist\n","batch_size = 256\n","train_iter, test_iter = load_data_mnist(batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c7rlKsg9rfdR","colab_type":"code","colab":{}},"source":["# criando a rede\n","net = nn.Sequential()\n","net.add(nn.Dense(128, activation='relu'),\n","        nn.Dense(64, activation='relu'),\n","        nn.Dense(10))\n","net.initialize(init.Normal(sigma=0.01), ctx=ctx) # observe aqui o uso do ctx! use a GPU!!\n","\n","cross_entropy = gloss.SoftmaxCrossEntropyLoss()\n","lr = 0.5\n","trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"761_jrzHrfdT","colab_type":"code","outputId":"5932a32c-77cd-4844-b6bb-a9b92a340df4","colab":{"base_uri":"https://localhost:8080/","height":208},"executionInfo":{"status":"ok","timestamp":1562081629931,"user_tz":180,"elapsed":69820,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}}},"source":["num_epochs = 10\n","train_validate(net, train_iter, test_iter, batch_size, trainer, cross_entropy, \n","               ctx, num_epochs)"],"execution_count":73,"outputs":[{"output_type":"stream","text":["training on gpu(0)\n","epoch 1, train loss 1.3082, train acc 0.527, test loss 0.3096, test acc 0.906, time 6.1 sec\n","epoch 2, train loss 0.2486, train acc 0.925, test loss 0.1578, test acc 0.950, time 6.8 sec\n","epoch 3, train loss 0.1481, train acc 0.955, test loss 0.1323, test acc 0.959, time 7.1 sec\n","epoch 4, train loss 0.1084, train acc 0.967, test loss 0.1060, test acc 0.967, time 7.2 sec\n","epoch 5, train loss 0.0904, train acc 0.972, test loss 0.0918, test acc 0.971, time 7.0 sec\n","epoch 6, train loss 0.0736, train acc 0.978, test loss 0.0927, test acc 0.973, time 6.9 sec\n","epoch 7, train loss 0.0625, train acc 0.981, test loss 0.0856, test acc 0.974, time 7.0 sec\n","epoch 8, train loss 0.0518, train acc 0.984, test loss 0.0813, test acc 0.976, time 7.0 sec\n","epoch 9, train loss 0.0432, train acc 0.987, test loss 0.0773, test acc 0.976, time 6.9 sec\n","epoch 10, train loss 0.0376, train acc 0.989, test loss 0.0779, test acc 0.978, time 6.8 sec\n"],"name":"stdout"}]}]}