{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04.1 - Problemas_conv.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Ed03SC1Jm9Yy","colab_type":"text"},"source":["# Problemas\n","\n","Como semana passada, nesta prática iremos usar tudo que aprendemos durante a semana.\n","Logo, **seu objetivo é determinar e implementar um modelo para cada problema.**\n","\n","Lembre-se de definir:\n","\n","1. uma arquitetura (tentem usar tanto arquiteturas existentes como propor novas usando camadas de convolução, pooling, e densas), \n","1. uma função de custo, e\n","1. um algoritmo de otimização (agora, como os problemas são maiores, será possível notar mais claramente a diferença entre diferentes algoritmos).\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Gp6CwWnFnTwb","colab_type":"text"},"source":["Antes de começar, vamos instalar o MXNet. Esse pequeno bloco de código abaixo é usado somente para instalar o MXNet para CUDA 10. Execute esse bloco somente uma vez e ignore possíveis erros levantados durante a instalação.\n","\n","**ATENÇÃO: a alteração deste bloco pode implicar em problemas na execução dos blocos restantes!**"]},{"cell_type":"code","metadata":{"id":"XW-VATPAldgt","colab_type":"code","outputId":"c77d8029-eeac-4a83-d1e1-5fedca4a7116","executionInfo":{"status":"ok","timestamp":1562764544492,"user_tz":180,"elapsed":52930,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":641}},"source":["!pip install mxnet-cu100\n","\n","# imports basicos\n","import time, os, sys, numpy as np\n","import mxnet as mx\n","from mxnet import autograd, gluon, init, nd\n","from mxnet.gluon import loss as gloss, nn, utils as gutils, data as gdata\n","\n","# Tenta encontrar GPU\n","def try_gpu():\n","    try:\n","        ctx = mx.gpu()\n","        _ = nd.zeros((1,), ctx=ctx)\n","    except mx.base.MXNetError:\n","        ctx = mx.cpu()\n","    return ctx\n","\n","ctx = try_gpu()\n","ctx"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting mxnet-cu100\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/91/b5c2692297aa5b8c383e0da18f9208fc6d5519d981c03266abfbde897c41/mxnet_cu100-1.4.1-py2.py3-none-manylinux1_x86_64.whl (488.3MB)\n","\u001b[K     |████████████████████████████████| 488.3MB 49kB/s \n","\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1 (from mxnet-cu100)\n","  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n","Collecting numpy<1.15.0,>=1.8.2 (from mxnet-cu100)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c4/395ebb218053ba44d64935b3729bc88241ec279915e72100c5979db10945/numpy-1.14.6-cp36-cp36m-manylinux1_x86_64.whl (13.8MB)\n","\u001b[K     |████████████████████████████████| 13.8MB 41.9MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.6.16)\n","\u001b[31mERROR: spacy 2.1.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n","\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fastai 1.0.54 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: blis 0.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: graphviz, numpy, mxnet-cu100\n","  Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","  Found existing installation: numpy 1.16.4\n","    Uninstalling numpy-1.16.4:\n","      Successfully uninstalled numpy-1.16.4\n","Successfully installed graphviz-0.8.4 mxnet-cu100-1.4.1 numpy-1.14.6\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["gpu(0)"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"g9u0pCOtlWLu","colab_type":"code","colab":{}},"source":["# funções básicas\n","def _get_batch(batch, ctx):\n","    \"\"\"Return features and labels on ctx.\"\"\"\n","    features, labels = batch\n","    if labels.dtype != features.dtype:\n","        labels = labels.astype(features.dtype)\n","    return (gutils.split_and_load(features, ctx),\n","            gutils.split_and_load(labels, ctx), features.shape[0])\n","\n","# Função usada para calcular acurácia\n","def evaluate_accuracy(data_iter, net, loss, ctx=[mx.cpu()]):\n","    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n","    if isinstance(ctx, mx.Context):\n","        ctx = [ctx]\n","    acc_sum, n, l = nd.array([0]), 0, 0\n","    for batch in data_iter:\n","        features, labels, _ = _get_batch(batch, ctx)\n","        for X, y in zip(features, labels):\n","            # X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            y = y.astype('float32')\n","            y_hat = net(X)\n","            l += loss(y_hat, y).sum()\n","            acc_sum += (y_hat.argmax(axis=1) == y).sum().copyto(mx.cpu())\n","            n += y.size\n","        acc_sum.wait_to_read()\n","    return acc_sum.asscalar() / n, l.asscalar() / n\n","  \n","# Função usada no treinamento e validação da rede\n","def train_validate(net, train_iter, test_iter, batch_size, trainer, loss, ctx,\n","                   num_epochs):\n","    print('training on', ctx)\n","    for epoch in range(num_epochs):\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","        for X, y in train_iter:\n","            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            with autograd.record():\n","                y_hat = net(X)\n","                l = loss(y_hat, y).sum()\n","            l.backward()\n","            trainer.step(batch_size)\n","            y = y.astype('float32')\n","            train_l_sum += l.asscalar()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n","            n += y.size\n","        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss, ctx)\n","        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n","              'test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_loss, \n","                 test_acc, time.time() - start))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ng3GdclS4qtx","colab_type":"text"},"source":["## Problema 1\n","\n","Neste segundo problema, classificaremos imagens de sensoriamento remoto de plantações de café do dataset público [Brazilian Coffee Scenes](http://www.patreo.dcc.ufmg.br/2017/11/12/brazilian-coffee-scenes-dataset/).\n","Neste caso, , vamos receber imagens de $64\\times 64$ pixels e classificá-las entre duas classes: \n","\n","1. café, e \n","2. não café."]},{"cell_type":"code","metadata":{"id":"xOMwqXYsBzqY","colab_type":"code","colab":{}},"source":["!wget http://www.patreo.dcc.ufmg.br/wp-content/uploads/2017/11/brazilian_coffee_dataset.zip\n","!unzip -q brazilian_coffee_dataset.zip\n","\n","class CoffeeDataset(gluon.data.Dataset):\n","    def __init__(self, root, train=False, calc_norm=False, has_norm=False):\n","        self.root = root\n","        self.train = train\n","        self.calc_norm = calc_norm\n","        self.has_norm = has_norm\n","        self.load_images()\n","\n","    def load_images(self):\n","        self.img_list, self.labels = self.read_images(root=self.root)\n","        \n","    def read_images(self, root):\n","        img_list, labels = [], []\n","        if self.train is True:\n","          for i in range(1,5):\n","            data_file = open(os.path.join(root, 'fold' + str(i+1) + '.txt'), \"r\")  # arquivo com nome das imagens\n","            data_list = [i.replace('\\n', '') for i in data_file.readlines()]\n","            for row in data_list:\n","                img_name = '.'.join(row.split('.')[1:])\n","                img_list.append(os.path.join(root, 'fold' + str(i+1), img_name + '.jpg'))\n","                labels.append(0 if row.split('.')[0] == 'coffee' else 1)\n","        else:\n","            data_file = open(os.path.join(root, 'fold1.txt'), \"r\")  # arquivo com nome das imagens\n","            data_list = [i.replace('\\n', '') for i in data_file.readlines()]\n","            for row in data_list:\n","                img_name = '.'.join(row.split('.')[1:])\n","                img_list.append(os.path.join(root, 'fold1', img_name + '.jpg'))\n","                labels.append(0 if row.split('.')[0] == 'coffee' else 1)\n"," \n","        return img_list, labels\n","\n","    def __getitem__(self, item):\n","        if self.has_norm is True:\n","            cur_img = self.normalize_image(mx.image.imread(self.img_list[item]).astype('float32'))\n","        else:\n","            cur_img = mx.image.imread(self.img_list[item])\n","        cur_label = self.labels[item]\n","        return cur_img, cur_label\n","        \n","    def __len__(self):\n","        return len(self.img_list)\n","      \n","    def normalize_image(self, img):\n","        if self.calc_norm is True:\n","          for i in range(img.shape[2]):\n","              mu = nd.mean(img[:, :, i])\n","              std = nd.sqrt(nd.mean((img[:, :, i] - mu)**2))\n","              img[:, :, i] = ((img[:, :, i] - mu) / std)\n","        else:\n","          img = img/255.0\n","          normalized = mx.image.color_normalize(img,\n","                                                mean=mx.nd.array([0.485, 0.456, 0.406]),\n","                                                std=mx.nd.array([0.229, 0.224, 0.225]))\n","        return img\n","      \n","      \n","def load_data(dataset, root, batch_size, resize=None):\n","    transformer = []\n","    if resize:\n","        transformer += [gdata.vision.transforms.Resize(resize)]\n","    transformer += [gdata.vision.transforms.ToTensor()]\n","    transformer = gdata.vision.transforms.Compose(transformer)\n","\n","    train = dataset(root=root, train=True)\n","    test = dataset(root=root, train=False)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = gdata.DataLoader(train.transform_first(transformer), \n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = gdata.DataLoader(test.transform_first(transformer), \n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","  \n","# carregamento do dado\n","train_iter, test_iter = load_data(CoffeeDataset, 'brazilian_coffee_scenes', batch_size, resize=227)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"77y3sBhm42Aa","colab_type":"text"},"source":["## Problema 2\n","\n","Neste segundo problema, classificaremos imagens gerais de sensoriamento remoto do dataset público [UCMerced](http://weegee.vision.ucmerced.edu/datasets/landuse.html).\n","Neste caso, vamos receber imagens de $256\\times 256$ pixels e classificá-las entre 21 classes: \n","\n","1. agricultural\n","1. airplane\n","1. baseballdiamond\n","1. beach\n","1. buildings\n","1. chaparral\n","1. denseresidential\n","1. forest\n","1. freeway\n","1. golfcourse\n","1. harbor\n","1. intersection\n","1. mediumresidential\n","1. mobilehomepark\n","1. overpass\n","1. parkinglot\n","1. river\n","1. runway\n","1. sparseresidential\n","1. storagetanks\n","1. tenniscourt"]},{"cell_type":"code","metadata":{"id":"kjMo5ZHJ44Tx","colab_type":"code","outputId":"34b8f184-3f2d-4116-91cb-b9f81c03cd53","executionInfo":{"status":"ok","timestamp":1562797996633,"user_tz":180,"elapsed":16483,"user":{"displayName":"Keiller Nogueira","photoUrl":"https://lh5.googleusercontent.com/-OSbB3k7-l84/AAAAAAAAAAI/AAAAAAAAAac/z8WNFFAmye0/s64/photo.jpg","userId":"03938009311988397527"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["!wget http://weegee.vision.ucmerced.edu/datasets/UCMerced_LandUse.zip\n","!unzip -q UCMerced_LandUse.zip\n","\n","class UCMercedDataset(gluon.data.Dataset):\n","    def __init__(self, root, train=False, calc_norm=False, has_norm=False):\n","        self.root = root\n","        self.train = train\n","        self.calc_norm = calc_norm\n","        self.has_norm = has_norm\n","        self.load_images()\n","\n","    def load_images(self):\n","        self.img_list, self.labels = self.read_images(root=self.root)\n","        \n","    def read_images(self, root):\n","        img_list, labels = [], []\n","        if self.train is True:\n","          for cat, folder in enumerate(os.listdir(self.root)):\n","            for num, img_name in enumerate(os.listdir(os.path.join(self.root, folder))):\n","                if num < 80:\n","                  img_list.append(os.path.join(self.root, folder, img_name))\n","                  labels.append(cat)\n","        else:\n","          for cat, folder in enumerate(os.listdir(os.path.join(self.root))):\n","            for num, img_name in enumerate(os.listdir(os.path.join(self.root, folder))):\n","                if num >= 80:\n","                  img_list.append(os.path.join(self.root, folder, img_name))\n","                  labels.append(cat)\n"," \n","        return img_list, labels\n","\n","    def __getitem__(self, item):\n","        if self.has_norm is True:\n","            cur_img = self.normalize_image(mx.image.imread(self.img_list[item]).astype('float32'))\n","        else:\n","            cur_img = mx.image.imread(self.img_list[item])\n","        cur_label = self.labels[item]\n","        return cur_img, cur_label\n","        \n","    def __len__(self):\n","        return len(self.img_list)\n","      \n","    def normalize_image(self, img):\n","        if self.calc_norm is True:\n","          for i in range(img.shape[2]):\n","              mu = nd.mean(img[:, :, i])\n","              std = nd.sqrt(nd.mean((img[:, :, i] - mu)**2))\n","              img[:, :, i] = ((img[:, :, i] - mu) / std)\n","        else:\n","          img = img/255.0\n","          normalized = mx.image.color_normalize(img,\n","                                                mean=mx.nd.array([0.485, 0.456, 0.406]),\n","                                                std=mx.nd.array([0.229, 0.224, 0.225]))\n","        return img\n","      \n","      \n","def load_data(dataset, root, batch_size, resize=None):\n","    transformer = []\n","    if resize:\n","        transformer += [gdata.vision.transforms.Resize(resize)]\n","    transformer += [gdata.vision.transforms.ToTensor()]\n","    transformer = gdata.vision.transforms.Compose(transformer)\n","\n","    train = dataset(root=root, train=True)\n","    test = dataset(root=root, train=False)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = gdata.DataLoader(train.transform_first(transformer), \n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = gdata.DataLoader(test.transform_first(transformer), \n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","  \n","# carregamento do dado\n","train_iter, test_iter = load_data(UCMercedDataset, os.path.join('UCMerced_LandUse', 'Images'), batch_size, resize=227)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2019-07-10 22:33:01--  http://weegee.vision.ucmerced.edu/datasets/UCMerced_LandUse.zip\n","Resolving weegee.vision.ucmerced.edu (weegee.vision.ucmerced.edu)... 169.236.184.65\n","Connecting to weegee.vision.ucmerced.edu (weegee.vision.ucmerced.edu)|169.236.184.65|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 332468434 (317M) [application/zip]\n","Saving to: ‘UCMerced_LandUse.zip’\n","\n","UCMerced_LandUse.zi 100%[===================>] 317.07M  55.7MB/s    in 8.0s    \n","\n","2019-07-10 22:33:10 (39.6 MB/s) - ‘UCMerced_LandUse.zip’ saved [332468434/332468434]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Nf_I82DJC8SZ","colab_type":"text"},"source":["## Problema 3\n","\n","No terceiro problema, classificaremos imagens genéricas de textura do dataset público [*Describable Textures Dataset*](http://www.robots.ox.ac.uk/~vgg/data/dtd/).\n","Neste caso, vamos receber imagens com tamanho variado (de $300\\times 300$ pixels até $640\\times 640$) e classificá-las entre 47 classes: \n","\n","1.  banded\n","1.  blotchy\n","1.  braided\n","1.  bubbly\n","1.  bumpy\n","1.  chequered\n","1.  cobwebbed\n","1.  cracked\n","1.  crosshatched\n","1.  crystalline\n","1.  dotted\n","1.  fibrous\n","1.  flecked\n","1.  freckled\n","1.  frilly\n","1.  gauzy\n","1.  grid\n","1.  grooved\n","1.  honeycombed\n","1.  interlaced\n","1.  knitted\n","1.  lacelike\n","1.  lined\n","1.  marbled\n","1.  matted\n","1.  meshed\n","1.  paisley\n","1.  perforated\n","1.  pitted\n","1.  pleated\n","1.  polka-dotted\n","1.  porous\n","1.  potholed\n","1.  scaly\n","1.  smeared\n","1.  spiralled\n","1.  sprinkled\n","1.  stained\n","1.  stratified\n","1.  striped\n","1.  studded\n","1.  swirly\n","1.  veined\n","1.  waffled\n","1.  woven\n","1.  wrinkled\n","1.  zigzagged"]},{"cell_type":"code","metadata":{"id":"s43Fig2FJALp","colab_type":"code","colab":{}},"source":["!wget http://www.robots.ox.ac.uk/~vgg/data/dtd/download/dtd-r1.0.1.tar.gz\n","!tar -xzf dtd-r1.0.1.tar.gz\n","\n","class TextureDataset(gluon.data.Dataset):\n","    def __init__(self, root, train=False, calc_norm=False, has_norm=False):\n","        self.root = root\n","        self.train = train\n","        self.calc_norm = calc_norm\n","        self.has_norm = has_norm\n","        self.le = {'banded': 0, 'blotchy': 1, 'braided': 2, 'bubbly': 3, 'bumpy': 4, 'chequered': 5, 'cobwebbed': 6, 'cracked': 7, 'crosshatched': 8, 'crystalline': 9, 'dotted': 10, 'fibrous': 11, 'flecked': 12, 'freckled': 13, 'frilly': 14, 'gauzy': 15, 'grid': 16, 'grooved': 17, 'honeycombed': 18, 'interlaced': 19, 'knitted': 20, 'lacelike': 21, 'lined': 22, 'marbled': 23, 'matted': 24, 'meshed': 25, 'paisley': 26, 'perforated': 27, 'pitted': 28, 'pleated': 29, 'polka-dotted': 30, 'porous': 31, 'potholed': 32, 'scaly': 33, 'smeared': 34, 'spiralled': 35, 'sprinkled': 36, 'stained': 37, 'stratified': 38, 'striped': 39, 'studded': 40, 'swirly': 41, 'veined': 42, 'waffled': 43, 'woven': 44, 'wrinkled': 45, 'zigzagged': 46}\n","        self.load_images()\n","\n","    def load_images(self):\n","        self.img_list, self.labels = self.read_images(root=self.root)\n","\n","    def read_images(self, root):\n","        img_list, labels = [], []\n","        if self.train is True:\n","            data_file = open(os.path.join(root, 'labels', 'train1.txt'), \"r\")  # arquivo com nome das imagens\n","            data_list = [i.replace('\\n', '') for i in data_file.readlines()]\n","            for img_path in data_list:\n","                img_list.append(os.path.join(root, 'images', img_path))\n","                labels.append(self.le[img_path.split('/')[0]])\n","                \n","            data_file = open(os.path.join(root, 'labels', 'val1.txt'), \"r\")  # arquivo com nome das imagens\n","            data_list = [i.replace('\\n', '') for i in data_file.readlines()]\n","            for img_path in data_list:\n","                img_list.append(os.path.join(root, 'images', img_path))\n","                labels.append(self.le[img_path.split('/')[0]])\n","        else:\n","            data_file = open(os.path.join(root, 'labels', 'test1.txt'), \"r\")  # arquivo com nome das imagens\n","            data_list = [i.replace('\\n', '') for i in data_file.readlines()]\n","            for img_path in data_list:\n","                img_list.append(os.path.join(root, 'images', img_path))\n","                labels.append(self.le[img_path.split('/')[0]])\n","\n","        return img_list, labels\n","\n","    def __getitem__(self, item):\n","        if self.has_norm is True:\n","            cur_img = self.normalize_image(mx.image.imread(self.img_list[item]).astype('float32'))\n","        else:\n","            cur_img = mx.image.imread(self.img_list[item])\n","        cur_label = self.labels[item]\n","        return cur_img, cur_label\n","        \n","    def __len__(self):\n","        return len(self.img_list)\n","      \n","    def normalize_image(self, img):\n","        if self.calc_norm is True:\n","          for i in range(img.shape[2]):\n","              mu = nd.mean(img[:, :, i])\n","              std = nd.sqrt(nd.mean((img[:, :, i] - mu)**2))\n","              img[:, :, i] = ((img[:, :, i] - mu) / std)\n","        else:\n","          img = img/255.0\n","          normalized = mx.image.color_normalize(img,\n","                                                mean=mx.nd.array([0.485, 0.456, 0.406]),\n","                                                std=mx.nd.array([0.229, 0.224, 0.225]))\n","        return img\n","      \n","      \n","def load_data(dataset, root, batch_size, resize=None):\n","    transformer = []\n","    if resize:\n","        transformer += [gdata.vision.transforms.Resize(resize)]\n","    transformer += [gdata.vision.transforms.ToTensor()]\n","    transformer = gdata.vision.transforms.Compose(transformer)\n","\n","    train = dataset(root=root, train=True)\n","    test = dataset(root=root, train=False)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","    train_iter = gdata.DataLoader(train.transform_first(transformer), \n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = gdata.DataLoader(test.transform_first(transformer), \n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","  \n","# carregamento do dado\n","train_iter, test_iter = load_data(TextureDataset, os.path.join('dtd'), batch_size, resize=227)"],"execution_count":0,"outputs":[]}]}