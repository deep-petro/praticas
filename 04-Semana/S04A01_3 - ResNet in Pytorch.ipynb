{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NG-mVsVuE0if"
   },
   "source": [
    "# Preâmbulo\n",
    "\n",
    "Imports, funções, downloads e instalação do Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71858,
     "status": "ok",
     "timestamp": 1563140259513,
     "user": {
      "displayName": "Hugo Neves",
      "photoUrl": "https://lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s64/photo.jpg",
      "userId": "03449378890045249481"
     },
     "user_tz": 180
    },
    "id": "FQ65_lev3RXO",
    "outputId": "5f2521de-a518-431f-eacf-490971444662"
   },
   "outputs": [],
   "source": [
    "# Reinstalling torch with the right CUDA bindings.\n",
    "!pip3 install -U https://download.pytorch.org/whl/cu100/torch-1.1.0-cp36-cp36m-linux_x86_64.whl\n",
    "!pip3 install -U https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp36-cp36m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEHmMCjR4PJw"
   },
   "outputs": [],
   "source": [
    "# Basic imports.\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "from torch.backends import cudnn\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73706,
     "status": "ok",
     "timestamp": 1563140261389,
     "user": {
      "displayName": "Hugo Neves",
      "photoUrl": "https://lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s64/photo.jpg",
      "userId": "03449378890045249481"
     },
     "user_tz": 180
    },
    "id": "RwhRUUlc4j23",
    "outputId": "a8df06c0-913c-4334-cc7e-ad33146103c1"
   },
   "outputs": [],
   "source": [
    "# Setting predefined arguments.\n",
    "args = {\n",
    "    'epoch_num': 50,      # Number of epochs.\n",
    "    'n_classes': 10,      # Number of classes.\n",
    "    'lr': 1e-4,           # Learning rate.\n",
    "    'weight_decay': 5e-4, # L2 penalty.\n",
    "    'momentum': 0.9,      # Momentum.\n",
    "    'num_workers': 3,     # Number of workers on data loader.\n",
    "    'batch_size': 200,    # Mini-batch size.\n",
    "    'w_size': 224,        # Width size for image resizing.\n",
    "    'h_size': 224,        # Height size for image resizing.\n",
    "}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    args['device'] = torch.device('cuda')\n",
    "else:\n",
    "    args['device'] = torch.device('cpu')\n",
    "\n",
    "print(args['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "20kc9tHQ59ba"
   },
   "source": [
    "# O pacote Torchvision\n",
    "\n",
    "Assim como no MXNet, o subpacote [datasets](https://pytorch.org/docs/stable/torchvision/datasets.html) do [torchvision](https://pytorch.org/docs/stable/torchvision/index.html) do Pytorch possui dataloaders para vários datasets conhecidos da literatura de Visão Computacional. O CIFAR10, já usado previamente no curso, é um desses dataset clássicos de classificação que possuem implementações que podem ser carregados por meio de uma única linha de código. Outros datasets clássicos presentes no torchvision são: MNIST (classificação), Fasion-MNIST (classificação), ImageNet (classificação), VOC (segmentação e detecção), COCO (detecção e captioning), etc. No bloco de código abaixo são carregados os datasets de treino e teste do CIFAR10 e seus respectivos dataloaders.\n",
    "\n",
    "O torchvision também possui outras funções de apoio ao treino de modelos para Deep Learning em imagens, como a definição de modelos (pré-treinados ou não) no subpacote [models](https://pytorch.org/docs/stable/torchvision/models.html) e a possibilidade de realizar pré-processamentos em imagens (incluindo Data Augmentation) por meio de transformações comuns em imagens no subpacote [transforms](https://pytorch.org/docs/stable/torchvision/transforms.html). Essas transformações também são demonstradas no código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4402,
     "status": "ok",
     "timestamp": 1563140639982,
     "user": {
      "displayName": "Hugo Neves",
      "photoUrl": "https://lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s64/photo.jpg",
      "userId": "03449378890045249481"
     },
     "user_tz": 180
    },
    "id": "b1QQiNTvZ8OM",
    "outputId": "5a867976-f902-4d1d-9492-d3c30cd022ba"
   },
   "outputs": [],
   "source": [
    "# Root directory for the dataset (to be downloaded).\n",
    "root = './'\n",
    "\n",
    "# Data Augmentation transforms.\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.RandomCrop((75, 75)),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Setting datasets and dataloaders.\n",
    "train_set = datasets.CIFAR10(root,\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=data_transform)\n",
    "test_set = datasets.CIFAR10(root,\n",
    "                            train=False,\n",
    "                            download=False,\n",
    "                            transform=data_transform)\n",
    "    \n",
    "for iters in range(5):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "    for i, test_data in enumerate(test_set):\n",
    "\n",
    "        if i >= 5:\n",
    "            break\n",
    "    \n",
    "        test_img, _ = test_data\n",
    "\n",
    "        ax[i].imshow(test_img.numpy().transpose(1, 2, 0))\n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_xticks([])\n",
    "        ax[i].set_title('Image ' + str(i))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48824,
     "status": "ok",
     "timestamp": 1563039384162,
     "user": {
      "displayName": "Hugo Neves",
      "photoUrl": "https://lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s64/photo.jpg",
      "userId": "03449378890045249481"
     },
     "user_tz": 180
    },
    "id": "Vi3Zh8fQ4X_3",
    "outputId": "89bd546a-9951-4995-d733-40970ca30579"
   },
   "outputs": [],
   "source": [
    "# Root directory for the dataset (to be downloaded).\n",
    "root = './'\n",
    "\n",
    "# Setting transforms (resizing, conversion to tensor and normalizing).\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((args['h_size'], args['w_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Setting datasets and dataloaders.\n",
    "train_set = datasets.CIFAR10(root,\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=data_transform)\n",
    "test_set = datasets.CIFAR10(root,\n",
    "                            train=False,\n",
    "                            download=False,\n",
    "                            transform=data_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set,\n",
    "                          args['batch_size'],\n",
    "                          num_workers=args['num_workers'],\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(test_set,\n",
    "                         args['batch_size'],\n",
    "                         num_workers=args['num_workers'],\n",
    "                         shuffle=False)\n",
    "\n",
    "# Printing training and testing dataset sizes.\n",
    "print('Size of training set: ' + str(len(train_set)) + ' samples')\n",
    "print('Size of test set: ' + str(len(test_set)) + ' samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "drOsx-32Ifo1"
   },
   "source": [
    "# Programação Orientada a Objetos\n",
    "\n",
    "Faz-se necessário o uso de  [Programação Orientada a Objetos](https://www.tutorialspoint.com/python/python_classes_objects.htm) (POO) à medida que se começa a lidar com tarefas mais específicas tratadas por algoritmos de Deep Learning. Algumas vantagens que POO trazem para a programação de algoritmos de Deep Learning são:\n",
    "\n",
    "1.   Organização do código. Criar uma arquitetura com centenas de camadas podendo conter várias *skip connections* no meio de um bloco de código, como vínhamos fazendo anteriormente, torna o nosso código desorganizado;\n",
    "2.   Reaproveitamento dos códigos básicos do framework (i.e. dataloaders, módulos/camadas de redes predefinidos, funções de perda, etc) para adaptá-los para novas tarefas minimizando a quantidade de código que necessita ser escrita;\n",
    "3.   Códigos escritos em formato POO podem ser reutilizados em outros pontos da aplicação. Arquiteturas como [DenseNets](https://arxiv.org/abs/1608.06993), [ResNets](https://arxiv.org/abs/1512.03385) ou [U-Nets](https://arxiv.org/abs/1505.04597) possuem blocos de código que se repetem, os quais podem ser simplificados com o uso de POO;\n",
    "4.   POO também permite uma melhor modularização do código, de forma que mudanças (i.e. loss function, arquitetura, dataloader, etc) possam ser feitas em módulos isolados sem afetar o resto do código.\n",
    "\n",
    "No caso da implementação de modelos usando classes no Pytorch, normalmente é preciso se preocupar apenas com a implementação de dois métodos: o *\\_\\_init\\_\\_()* e o *forward()*. O *\\_\\_init\\_\\_()* é conhecido como o construtor da classe e define a arquitetura da rede neural que é implementada pela classe, ou seja, é nesse método que se definem as camadas da rede neural. Já o *forward()* serve para definir o fluxo de dados que passará pelas camadas definidas no *\\_\\_init\\_\\_()*. O *forward()* recebe sempre como entrada os dados que passarão pelo modelo e deve retornar o output do modelo após processar esses dados de entrada ao longo de suas camadas. É notável que entre as camadas convolucionais e as camadas Fully Connected, faz-se necessário chamar o método [*view()*](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view) para linearizar os dados do tensor.\n",
    "\n",
    "Também é preciso lembrar de sempre definir a classe em que o modelo está sendo implementado como subclasse de *nn.Module*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MWKYCVh5oFtL"
   },
   "source": [
    "# Redes Residuais (ResNets)\n",
    "\n",
    "Entre 2012 e 2015 a comunidade de Visão Computacional percebeu que redes mais profundas conseguiam capturar características semânticas mais úteis dos dados para tarefas de reconhecimento de imagens (i.e. classificação, segmentação, detecção...). Porém, redes mais profundas que as maiores arquiteturas da época -- como a [VGG](https://arxiv.org/abs/1409.1556) e a [Inception](https://arxiv.org/abs/1409.4842) -- sofriam de um problema chamado **Vanishing Gradient**.\n",
    "\n",
    "![VGG](https://www.researchgate.net/profile/Clifford_Yang/publication/325137356/figure/fig2/AS:670371271413777@1536840374533/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means_W640.jpg)\n",
    "\n",
    "![Inception](https://miro.medium.com/max/700/1*uW81y16b-ptBDV8SIT1beQ.png)\n",
    "\n",
    "\n",
    "O **Vanishing Gradient** se torna mais problemático em redes mais profundas porque o gradiente dos erros precisa backpropagar desde a última camada até o começo da rede. Dessa forma, as últimas camadas conseguem ser treinadas de forma eficiente, mas o gradiente dos erros vai desaparecendo à medida em que backpropaga pela rede, praticamente impossibilitando o treinamento das primeiras camadas. Assim, foi constatado que uma rede com, por exemplo, 34 camadas acabava por conseguir resultados piores que uma rede com apenas 18 camadas.\n",
    "\n",
    "![Rede Não Residual](https://www.dropbox.com/s/pq190al5b3qv194/normal_18_vs_34_layers.png?dl=1)\n",
    "\n",
    "No final de 2015 foi proposta uma solução para o **Vanishing Gradient** na forma de **Blocos Residuais** que, juntos, formam **Redes Residuais** [**(ResNets)**](https://arxiv.org/abs/1512.03385). Esses blocos residuais recebem uma entrada $x$ e a alimentam para um bloco convolucional ($\\mathcal{F}(x)$) composto por:\n",
    "\n",
    "1.   Convolução 3x3;\n",
    "2.   Batch Normalization;\n",
    "3.   ReLU;\n",
    "4.   Convolução 3x3;\n",
    "5.   Batch Normalization.\n",
    "\n",
    "A saída $\\mathcal{F}(x)$ desse bloco, antes de ser passada por uma segunda ReLU, é passada em conjunto com a entrada $x$ para uma função identidade, que, no caso das **ResNets**, é uma simples soma. Dessa forma, a saída final de um **Bloco Residual** é dada por: $\\mathcal{F}(x) + x$. O esquema de um **Bloco Residual** pode ser visto na figura abaixo.\n",
    "\n",
    "![Bloco Residual](https://www.dropbox.com/s/ezydump33p95ohc/residual_block.png?dl=1)\n",
    "\n",
    "Como pode ser visto na imagem a seguir, com o uso de blocos residuais, uma arquitetura com 34 camadas consegue resultados melhores que uma arquitetura com apenas 18 camadas. Esses resultados evidenciam que o uso da soma como **identity function** de fato permite que o backward treine mais efetivamente as primeiras camadas das **ResNets**. **ResNets** permitiram que CNNs chegassem até a casa das 100 camadas. A maior **ResNet** usada na prática possui 152 camadas, o que a deixa impraticável de imprimir numa figura como é mostrado abaixo na ResNet34.\n",
    "\n",
    "![Rede Residual](https://www.dropbox.com/s/q4wcjwf8qj4xjrn/resnet_18_vs_34_layers.png?dl=1)\n",
    "\n",
    "Como pode ser visto nas imagens abaixo, ResNets (e outras arquiteturas modernas como a [VGG](https://arxiv.org/abs/1409.1556) e as [DenseNets](https://arxiv.org/abs/1608.06993) são compostas basicamente de convoluções com kernels de tamanho 3x3. Além disso, é notável na arquitetura residual (à direita) a presença dos \"atalhos\" para o gradiente  na forma das funções identidade que ajudam no treinamento das primeiras camadas durante o backpropagation.\n",
    "\n",
    "![VGG vs. Plain34 vs. ResNet34](https://www.dropbox.com/s/d2w3h7dlumgclx2/vgg_plain34_resnet34.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZskOnbWrhzNJ"
   },
   "source": [
    "# Atividade Prática\n",
    "\n",
    "1.   Completar a classe *ResidualBlock()*. Devem ser complementados os métodos *\\_\\_init\\_\\_()* e *forward()*. Atenção para a implementação da função identidade no *forward()* e para a compatibilidade do número de canais de entrada e saída de cada bloco residual. Quando a variável *in_planes* tiver um valor diferente da *out_planes*, uma convolução 1x1 deve ser instanciada para transformar o número de canais da entrada *in_planes* nos feature maps para *out_planes*. Isso vai permitir que blocos residuais que tenham números de canais entrada e saída diferentes possam ser somados no *forward()* para o cálculo da função identidade.\n",
    "2.   Completar a classe ResNet criando um bloco convolucional no começo da rede, dois blocos residuais no meio. Novamente devem ser implementados os métodos *\\_\\_init\\_\\_()* e *forward()*.\n",
    "3.   Definir o otimizador que fará a rede convergir. Podem ser escolhidos diferentes otimizadores de acordo com o que está implementado no pacote [*optim*](https://pytorch.org/docs/stable/optim.html).\n",
    "4.   Definir a loss function de acordo com o pacote [*nn*](https://pytorch.org/docs/stable/nn.html#loss-functions) que será utilizada para computar os gradientes no fim da rede. Deve ser escolhida a Cross Entropy, já que trata-se de uma tarefa de classificação de imagens.\n",
    "5.   Opcional: adicionar transformações diferentes nos dados (i.e. flips horizontais/verticais aleatórios, crops aleatórios, color jitter, rotações aleatórias, etc) usando o pacote [transforms](https://pytorch.org/docs/stable/torchvision/transforms.html) para realizar Data Augmentation.\n",
    "\n",
    "As funções de treino e teste já estão implementadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1109,
     "status": "ok",
     "timestamp": 1563041640380,
     "user": {
      "displayName": "Hugo Neves",
      "photoUrl": "https://lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s64/photo.jpg",
      "userId": "03449378890045249481"
     },
     "user_tz": 180
    },
    "id": "25PD5HF-8XxD",
    "outputId": "3e5c8965-cc51-4de8-b90c-4c5b76eadeac"
   },
   "outputs": [],
   "source": [
    "# Implementation of residual block to be reused.\n",
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_planes, out_planes):\n",
    "        \n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # TO DO: define first and second convolutional blocks.\n",
    "        \n",
    "        # If in_planes != out_planes, perform a 1x1 conv to match #channels.\n",
    "        self.conv1x1 = None\n",
    "        if in_planes != out_planes:\n",
    "            self.conv1x1 = # TO DO: define 1x1 convolution.\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        identity = x\n",
    "\n",
    "        # TO DO: forward on first conv block.\n",
    "        \n",
    "        # TO DO: forward on second conv block.\n",
    "        \n",
    "        # TO DO: return output.\n",
    "\n",
    "# ResNet18 implementation.\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        # TO DO: define first convolutional block:\n",
    "        #        1. conv with 7x7 kernel, 64 output channels, stride of 2,\n",
    "        #           padding of 3 and with no bias;\n",
    "        #        2. 2d batch normalization;\n",
    "        #        3. ReLU;\n",
    "        #        4. 2d max pool with 3x3 kernel, stride of 2 and padding of 1.\n",
    "\n",
    "\n",
    "        # TO DO: define first residual block + pooling:\n",
    "        #        1. instantiate residual block from class ResidualBlock with\n",
    "        #           number of output channels equal to 128;\n",
    "        #        2. 2d max pool with 3x3 kernel, stride of 2 and padding of 1.\n",
    "        \n",
    "        \n",
    "        # TO DO: define second residual block + pooling:\n",
    "        #        1. instantiate residual block from class ResidualBlock with\n",
    "        #           number of output channels equal to 128;\n",
    "        #        2. 2d max pool with 3x3 kernel, stride of 2 and padding of 1.\n",
    "        \n",
    "        # TO DO: define classifier:\n",
    "        #        1. define an nn.AdaptiveAvgPool2d(output_size(1, 1)), simmilar\n",
    "        #           to MXNet's GlobalPool2d();\n",
    "        #        2. define FC classification layer with 10 outputs.\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        \n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "    \n",
    "    # Function for randomly initializing weights.\n",
    "    def initialize_weights(self):\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,\n",
    "                                        mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # TO DO: forward on first conv block.\n",
    "        \n",
    "        # TO DO: forward on first residual block.\n",
    "        \n",
    "        # TO DO: forward on second residual block.\n",
    "        \n",
    "        # TO DO: forward on adaptive_pool.\n",
    "        \n",
    "        # TO DO: linearizing tensor to serve as input to FC layer.\n",
    "        \n",
    "        # TO DO: obtain 10 predictions (one for each class) on FC layer.\n",
    "        \n",
    "        # TO DO: return output.\n",
    "\n",
    "# Instantiating architecture.\n",
    "net = ResNet(args['n_classes']).to(args['device'])\n",
    "\n",
    "# Printing architecture.\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nS2l_pqAI0F2"
   },
   "source": [
    "# Definindo o otimizador\n",
    "\n",
    "O Pytorch possui vários otimizadores prontos no subpacote [optim](https://pytorch.org/docs/stable/optim.html), desde o SGD básico a otimizadores mais complexos e com taxas de aprendizado por parâmetro como o Adagrad, RMSProp e Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_-RN1wH-4bB"
   },
   "outputs": [],
   "source": [
    "# TO DO: define optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DVhOWUkWKU4f"
   },
   "source": [
    "# Definindo a loss\n",
    "\n",
    "O subpacote [nn](https://pytorch.org/docs/stable/nn.html) possui várias funções de perda para diferentes tarefas (i.e. Cross Entropy, Negative Log Likelihood, loss L1, MSE, Kullback Leibler Divergence, etc) implementadas por padrão.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NX_bmN3__LIK"
   },
   "outputs": [],
   "source": [
    "# TO DO: define loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXhZakGZK_kU"
   },
   "source": [
    "# Criando funções para Treino e Teste\n",
    "\n",
    "Iterando sobre os datasets/dataloaders de treino e teste do CIFAR10. Abaixo são implementadas a função *train()* que itera sobre os batches do dataset de treino e atualiza o modelo e a função *test()* que apenas realiza o forward dos dados de teste no modelo e calcula a acurácia no dataset de teste para o modelo no estado atual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCU5Gx9D_6xW"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, net, criterion, optimizer, epoch):\n",
    "\n",
    "    tic = time.time()\n",
    "    \n",
    "    # Setting network for training mode.\n",
    "    net.train()\n",
    "\n",
    "    # Lists for losses and metrics.\n",
    "    train_loss = []\n",
    "    \n",
    "    # Iterating over batches.\n",
    "    for i, batch_data in enumerate(train_loader):\n",
    "\n",
    "        # Obtaining images, labels and paths for batch.\n",
    "        inps, labs = batch_data\n",
    "        \n",
    "        # Casting to cuda variables.\n",
    "        inps = inps.to(args['device'])\n",
    "        labs = labs.to(args['device'])\n",
    "        \n",
    "        # Clears the gradients of optimizer.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forwarding.\n",
    "        outs = net(inps)\n",
    "\n",
    "        # Computing loss.\n",
    "        loss = criterion(outs, labs)\n",
    "\n",
    "        # Computing backpropagation.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Updating lists.\n",
    "        train_loss.append(loss.data.item())\n",
    "    \n",
    "    toc = time.time()\n",
    "    \n",
    "    train_loss = np.asarray(train_loss)\n",
    "    \n",
    "    # Printing training epoch loss and metrics.\n",
    "    print('--------------------------------------------------------------------')\n",
    "    print('[epoch %d], [train loss %.4f +/- %.4f], [training time %.2f]' % (\n",
    "        epoch, train_loss.mean(), train_loss.std(), (toc - tic)))\n",
    "    print('--------------------------------------------------------------------')\n",
    "    \n",
    "def test(test_loader, net, criterion, epoch):\n",
    "\n",
    "    tic = time.time()\n",
    "    \n",
    "    # Setting network for evaluation mode (not computing gradients).\n",
    "    net.eval()\n",
    "\n",
    "    # Lists for losses and metrics.\n",
    "    test_loss = []\n",
    "    prd_list = []\n",
    "    lab_list = []\n",
    "    \n",
    "    # Iterating over batches.\n",
    "    for i, batch_data in enumerate(train_loader):\n",
    "\n",
    "        # Obtaining images, labels and paths for batch.\n",
    "        inps, labs = batch_data\n",
    "\n",
    "        # Casting to cuda variables.\n",
    "        inps = inps.to(args['device'])\n",
    "        labs = labs.to(args['device'])\n",
    "\n",
    "        # Forwarding.\n",
    "        outs = net(inps)\n",
    "\n",
    "        # Computing loss.\n",
    "        loss = criterion(outs, labs)\n",
    "        \n",
    "        # Obtaining predictions.\n",
    "        prds = outs.data.max(dim=1)[1].cpu().numpy()\n",
    "        \n",
    "        # Updating lists.\n",
    "        test_loss.append(loss.data.item())\n",
    "        prd_list.append(prds)\n",
    "        lab_list.append(labs.detach().cpu().numpy())\n",
    "    \n",
    "    toc = time.time()\n",
    "    \n",
    "    # Computing accuracy.\n",
    "    acc = metrics.accuracy_score(np.asarray(lab_list).ravel(),\n",
    "                                 np.asarray(prd_list).ravel())\n",
    "    \n",
    "    test_loss = np.asarray(test_loss)\n",
    "    \n",
    "    # Printing training epoch loss and metrics.\n",
    "    print('--------------------------------------------------------------------')\n",
    "    print('[epoch %d], [test loss %.4f +/- %.4f], [acc %.4f], [testing time %.2f]' % (\n",
    "        epoch, test_loss.mean(), test_loss.std(), acc, (toc - tic)))\n",
    "    print('--------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ijo07bsTMFMs"
   },
   "source": [
    "# Iterando sobre epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11895686,
     "status": "ok",
     "timestamp": 1563053544452,
     "user": {
      "displayName": "Hugo Neves",
      "photoUrl": "https://lh6.googleusercontent.com/-yVVtZxPjhUQ/AAAAAAAAAAI/AAAAAAAAAfU/s1p3kfVzHaM/s64/photo.jpg",
      "userId": "03449378890045249481"
     },
     "user_tz": 180
    },
    "id": "RU2aYIob_zTu",
    "outputId": "3798a94b-32a3-4c50-87e4-739542c59946"
   },
   "outputs": [],
   "source": [
    "# Iterating over epochs.\n",
    "for epoch in range(1, args['epoch_num'] + 1):\n",
    "\n",
    "    # Training function.\n",
    "    train(train_loader, net, criterion, optimizer, epoch)\n",
    "\n",
    "    # Computing test loss and metrics.\n",
    "    test(test_loader, net, criterion, epoch)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "S04A01_3 - ResNet in Pytorch.ipynb",
   "provenance": [
    {
     "file_id": "1nNFHKuEo160gW6NUFeYhJphF2St_12Ri",
     "timestamp": 1563057623381
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:anaconda2]",
   "language": "python",
   "name": "conda-env-anaconda2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
