{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S04A04_1 - DenseNet in Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG-mVsVuE0if",
        "colab_type": "text"
      },
      "source": [
        "# Preâmbulo\n",
        "\n",
        "Imports, funções e downloads."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEHmMCjR4PJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic imports.\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwhRUUlc4j23",
        "colab_type": "code",
        "outputId": "8795b79c-a5b7-4974-dd81-f761b0cff5ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Setting predefined arguments.\n",
        "args = {\n",
        "    'epoch_num': 50,      # Number of epochs.\n",
        "    'n_classes': 10,      # Number of classes.\n",
        "    'lr': 1e-4,           # Learning rate.\n",
        "    'weight_decay': 5e-4, # L2 penalty.\n",
        "    'momentum': 0.9,      # Momentum.\n",
        "    'num_workers': 3,     # Number of workers on data loader.\n",
        "    'batch_size': 50,     # Mini-batch size.\n",
        "    'w_size': 224,        # Width size for image resizing.\n",
        "    'h_size': 224,        # Height size for image resizing.\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drOsx-32Ifo1",
        "colab_type": "text"
      },
      "source": [
        "# DenseNets\n",
        "\n",
        "As [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993) (DenseNets) surgiram em 2016 como um avanço em relação ao antigo estado da arte: as [ResNets](https://arxiv.org/abs/1512.03385). Essas redes, ao invés de focarem em estabilizar o treinamento para conseguir arquiteturas cada vez mais profundas, tinham em vista obter uma melhor **eficiência de parâmetros** com relação às suas antecessoras. Vários artigos entre 2015 e 2016 observaram que, apesar de serem altamente poderosas, as ResNets possuiam vários canais completamente redundantes que poderiam ser simplesmente ignorados no forward durante o teste sem afetar o desempenho final da rede. Isso indicava que essas redes possuiam uma baixa eficiência de parâmetros.\n",
        "\n",
        "As DenseNets surgiram como uma forma de mitigar esse problema dos canais convolucionais redundantes, mas ainda assim mantendo a característica da função identidade das ResNets que funciona essencialmente como uma **Skip Connection** para mitigar o problema do **Vanishing Gradient** durante o backpropagation. Enquanto ResNets usam uma soma como função de identidade, como vimos no começo da semana, DenseNets propuseram o uso de concatenações como funções identidades, assim como FCNs fazem. Porém, ao contrário das FCNs, cada bloco convolucional de uma DenseNet pode receber vários feature maps, mas quase sempre vai combinar esses canais de entrada em apenas alguns poucos canais de saída, efetivamente economizando parâmetros a serem computados. Abaixo pode ser visto um exemplo de um **Bloco Convolucional Denso**, como pode ser visto na figura abaixo.\n",
        "\n",
        "![Dense Block](https://www.dropbox.com/s/xmpfsei3rdyx2s5/DenseNets_Dense_Block.png?dl=1)\n",
        "\n",
        "Assim como no caso dos **Blocos Residuais** das ResNets, vários **Blocos Convolucionais Densos** são empilhados para formar uma DenseNet. Entre esses blocos são colocadas **Camadas de Transição** compostas simplesmente por convoluções 1x1 e average pooling. As **Camadas de Transição** servem para diminuir progressivamente as resoluções espaciais dos feature maps, as quais são preservadas dentro de cada **Bloco Denso**. **Camadas de Transição** também controlam a quantidade de feature maps que passam para o próximo **Bloco Denso** por meio da convolução 1x1. Por fim, assim como em praticamente todas as CNNs para classificação modernas (i.e. Inception, ResNets...), os canais que saem do último **Bloco Denso** são linearizados usando um **Global Average Pooling** e passados para uma camada **Fully Connected** que realiza a predição por classes.\n",
        "\n",
        "![DenseNet Architecture](https://www.dropbox.com/s/xj4lz2ykv977p6f/DenseNets_Architecture.png?dl=1)\n",
        "\n",
        "DenseNets se provaram muito mais eficientes em número de parâmetros e em [flops](https://pt.wikipedia.org/wiki/FLOPS), quando comparadas com as ResNets, como pode ser visto nos gráficos abaixo.\n",
        "\n",
        "![DenseNet vs. ResNet 1](https://www.dropbox.com/s/zdgzwh3hciex93y/DenseNets_vs_ResNets_1.png?dl=1)\n",
        "![DenseNet vs. ResNet 2](https://www.dropbox.com/s/c6oz6xpu3bkt306/DenseNets_vs_ResNets_2.png?dl=1)\n",
        "![DenseNet vs. ResNet 3](https://www.dropbox.com/s/dhageb200bogvds/DenseNets_vs_ResNets_3.png?dl=1)\n",
        "![DenseNet vs. ResNet 4](https://www.dropbox.com/s/flt39pmiy3bophr/DenseNets_vs_ResNets_4.png?dl=1)\n",
        "\n",
        "Comparando o desempenho de DenseNets em vários datasets, é visível que as DenseNets conseguem resultados melhores que todas as concorrentes com um número de parâmetros treináveis relativamente modesto.\n",
        "\n",
        "![DenseNet vs. Others](https://www.dropbox.com/s/en016pm6kocwj7m/DenseNets_vs_Other_Networks.png?dl=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqMfxbFMJtmP",
        "colab_type": "text"
      },
      "source": [
        "# Atividade Prática: Aproveitando DenseNet pré-treinada do Pytorch\n",
        "\n",
        "Aproveitar o resto dos códigos da S04A04_1 e adaptá-los para realizar classificação no CIFAR 10 usando a DenseNet121 pré-treinada do subpacote [*models*](https://pytorch.org/docs/stable/torchvision/models.html) do torchvision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk4sjZ_HnjY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using predefined and pretrained model of DenseNet121 on torchvision.\n",
        "net = # ..."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}