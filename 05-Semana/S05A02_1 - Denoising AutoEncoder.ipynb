{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S05A02_1 - Denoising AutoEncoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG-mVsVuE0if",
        "colab_type": "text"
      },
      "source": [
        "# Preâmbulo\n",
        "\n",
        "Imports, funções, downloads e instalação do Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEHmMCjR4PJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Basic imports.\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "from torch.backends import cudnn\n",
        "\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwhRUUlc4j23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting predefined arguments.\n",
        "args = {\n",
        "    'epoch_num': 10,      # Number of epochs.\n",
        "    'lr': 0.0005,         # Learning rate.\n",
        "    'weight_decay': 1e-5, # L2 penalty.\n",
        "    'num_workers': 3,     # Number of workers on data loader.\n",
        "    'batch_size': 50,     # Mini-batch size.\n",
        "    'print_freq': 1,      # Printing frequency.\n",
        "    'noise_std': 0.05,    # Artificial gaussian noise standard deviation.\n",
        "    'noise_prob': 0.05,   # Artificial salt-and-pepper noise probability.\n",
        "}\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20kc9tHQ59ba",
        "colab_type": "text"
      },
      "source": [
        "# Carregando o FashionMNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi3Zh8fQ4X_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Root directory for the dataset (to be downloaded).\n",
        "root = './'\n",
        "\n",
        "# Transformations over the dataset.\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Setting datasets and dataloaders.\n",
        "train_set = datasets.FashionMNIST(root,\n",
        "                                  train=True,\n",
        "                                  download=True,\n",
        "                                  transform=data_transforms)\n",
        "test_set = datasets.FashionMNIST(root,\n",
        "                                 train=False,\n",
        "                                 download=False,\n",
        "                                 transform=data_transforms)\n",
        "\n",
        "# Setting dataloaders.\n",
        "train_loader = DataLoader(train_set,\n",
        "                          args['batch_size'],\n",
        "                          num_workers=args['num_workers'],\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_set,\n",
        "                         args['batch_size'],\n",
        "                         num_workers=args['num_workers'],\n",
        "                         shuffle=False)\n",
        "\n",
        "# Printing training and testing dataset sizes.\n",
        "print('Size of training set: ' + str(len(train_set)) + ' samples')\n",
        "print('Size of test set: ' + str(len(test_set)) + ' samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drOsx-32Ifo1",
        "colab_type": "text"
      },
      "source": [
        "# Denoising AutoEncoder\n",
        "\n",
        "Tanto AEs Lineares quanto Convolucionais podem ser adaptados para tarefas diferentes da de redução de dimensionalidade e reconstrução de imagens. Ao adicionar ruído artificial às imagens de entrada antes de passá-las para a forward, por exemplo, é possível treinar um AE para aprender a ignorar esse ruído e reconstruir as imagens originais, efetivamente realizando uma filtragem de ruído treinável. Em suma, é isso que um Denoising AutoEncoder (DAE) faz, como mostra o esquema abaixo.\n",
        "\n",
        "![Denoising AE](https://www.dropbox.com/s/mekbapirkdvwkhx/Denoising_AE.png?dl=1)\n",
        "\n",
        "É perceptível que ainda é preciso ter amostras limpas de ruído para treinar esse tipo de método, tornando-o limitado em alguns cenários. Porém, utilizando o conhecimento que se tem sobre as distribuições de ruídos em diferentes tipos de imagens (i.e. [gaussiano](https://en.wikipedia.org/wiki/Additive_white_Gaussian_noise), [salt-and-pepper](https://en.wikipedia.org/wiki/Salt-and-pepper_noise), [ruído quântico](https://www.sciencedirect.com/topics/chemistry/quantum-noise), etc) e realizando algumas suposições sobre a natureza das imagens, é possível construir com pequenas alterações no AE tradicional um removedor de ruído específico para os dados de um certo domínio.\n",
        "\n",
        "O ruído salt-and-pepper é determinado pixel-a-pixel por uma distribuição de Bernoulli. Ou seja, dados $M$ pixels ${A_{0}, A_{1}, ..., A_{M-1}}$ de uma imagem $A$ e uma probabilidade $p$, cada pixel $A_{i}$ possui uma probabilidade $\\frac{p}{2}$ de ser setado para 0 e uma probabilidade $\\frac{p}{2}$ de ser setado para 1. No caso do ruído aditivo gaussiano, valores de uma imagem de ruído $B$ (tal que $B_{i} \\sim N(0, std)$) amostrada aleatoriamente são somados a todos os pixels da imagem $A$, resultando numa imagem $C = A + B$.\n",
        "\n",
        "Métodos mais modernos (i.e. [Noise2Noise](https://arxiv.org/pdf/1803.04189.pdf)) conseguem convergir sem a necessidade de dados não afetados pelos ruídos, tornando-os altamente aplicáveis em áreas como [imagens biomédicas](http://www.sprawls.org/ppmi2/NOISE/) ou [sensoriamento remoto](https://en.wikipedia.org/wiki/Synthetic-aperture_radar), as quais normalmente não possuem amostras \"limpas\" para treinamento de um DAE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu2-oXvWgb1e",
        "colab_type": "text"
      },
      "source": [
        "# Atividade Prática: modificando o AE Convolucional para remoção de ruído\n",
        "\n",
        "1.   Implemente uma função que adicione um ruído do tipo salt-and-pepper em todas as imagens de um batch. Essa função deve receber um tensor de entrada e uma probabilidade $p$ de que cada pixel seja setado para 0 ou para 1, que são os valores mínimos das imagens. Dica: função [*torch.rand_like()*](https://pytorch.org/docs/stable/torch.html#torch.rand_like);\n",
        "2.   Implemente uma função que adicione um ruído aditivo gaussiano em todas as imagens de um batch. Essa função deve receber um tensor de entrada e um desvio padrão $std$ da distribuição normal que será adicionada a cada pixel. Dica: função [*torch.randn_like()*](https://pytorch.org/docs/stable/torch.html#torch.randn_like);\n",
        "3.   Modifique a arquitetura do AE Convolucional da aula passada para quadruplicar a quantidade de canais em cada camada convolucional do Encoder e do Decoder. Como nossa preocupação não é mais gerar uma representação compacta dos dados e sim remover ruído, não precisamos mais ser tão econômicos com os canais das convoluções;\n",
        "4.   Modifique as funções *train()* e *test()* para adicionar ruído usando uma das duas funções a cima na variável *inps* antes de passá-la para a entrada do AE Convolucional;\n",
        "5.   Varie os valores de args\\['noise_std'\\] e args\\['noise_prob'\\] para ver até qual nível de ruído os AEs conseguem reconstruir fidedignamente as imagens originais.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQTd9Tgni96P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO: Adding Salt-and-Pepper with probability p.\n",
        "def add_salt_and_pepper_noise(tensor, p=0.05):\n",
        "    \n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJzQIxkQkMoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO DO: Inserting Additive Gaussian Noise with standard deviation std.\n",
        "def add_additive_gaussian_noise(tensor, std=0.1):\n",
        "    \n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}